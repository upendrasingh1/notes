https://ai.meta.com/blog/code-llama-large-language-model-coding/

https://github.com/ragntune/code-llama-finetune/blob/main/fine-tune-code-llama.ipynb
https://billtcheng2013.medium.com/codellama-fine-tuning-7d40e6ad33b4

https://medium.com/aimonks/code-llama-quick-start-guide-and-prompt-engineering-eb1de8758399

https://medium.com/@martin.p.dittgen/training-a-bert-model-from-scratch-on-a-single-nvidia-rtx-3060-1a7a2b1039a5

https://medium.com/innova-technology/efficient-fine-tuning-of-quantized-llama-2-da383228ee1e

(working) https://blog.ovhcloud.com/fine-tuning-llama-2-models-using-a-single-gpu-qlora-and-ai-notebooks/

https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c

https://huggingface.co/learn/cookbook/en/fine_tuning_code_llm_on_single_gpu


https://www.anthropic.com/research/building-effective-agents
https://huyenchip.com/2025/01/07/agents.html#agent_overview

https://simodev.medium.com/building-a-high-performance-rag-system-with-postgresql-and-deepseek-coder-143c278bb0a3

https://towardsdatascience.com/large-models-meet-big-data-spark-and-llms-in-harmony-5e2976b69b62/
